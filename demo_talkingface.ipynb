{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAobeWS6ILaD"
      },
      "source": [
        "## Preparations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "kgpExw3AsWfB",
        "outputId": "43423180-462f-4658-ef0c-fed183fdc0a6"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/yiranran/Audio-driven-TalkingFace-HeadPose.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "dZFmySCtsjkU",
        "outputId": "d5269148-c8b7-4ace-8d27-b03f298b8313"
      },
      "outputs": [],
      "source": [
        "cd Audio-driven-TalkingFace-HeadPose/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0_ZtzJjAZ9a"
      },
      "source": [
        "### Install python packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WrBEd4_isnK6",
        "outputId": "47df0f79-1890-4e71-9c9e-4324e0f1b5e4"
      },
      "outputs": [],
      "source": [
        "pip install -r requirements_colab.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J43IhexQJIf"
      },
      "source": [
        "### Use octave instead of matlab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "JufHm1PvBpar",
        "outputId": "20feaea0-4e9d-49c4-9b3d-10fd2fb2bd04"
      },
      "outputs": [],
      "source": [
        "!apt-get update"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "pV8Ztv0qz-Bn",
        "outputId": "a5cc8721-5729-4b75-d63f-26355570004c"
      },
      "outputs": [],
      "source": [
        "!apt install octave liboctave-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "_BNNdIL6QM0j",
        "outputId": "c38c38d4-99de-4378-c6a4-df7b3259230c"
      },
      "outputs": [],
      "source": [
        "!wget https://nchc.dl.sourceforge.net/project/octave/Octave%20Forge%20Packages/Individual%20Package%20Releases/image-2.12.0.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5sc32pk-QOC7",
        "outputId": "36c01366-bc40-4d1c-c43f-1e0bee64f494"
      },
      "outputs": [],
      "source": [
        "!octave --eval \"pkg install image-2.12.0.tar.gz\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7uyjgZRAUH8"
      },
      "source": [
        "### Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "Zdrp3qxv0S4A",
        "outputId": "84d661d5-8735-4199-a41e-62f43cc4a66f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84H0xglbIDon"
      },
      "source": [
        "### Copy pre-trained models here and unzip them.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "dD7gjDoG07hG",
        "outputId": "d0080f37-c906-47b1-f276-e6b56515fb3c"
      },
      "outputs": [],
      "source": [
        "!unzip /content/gdrive/My\\ Drive/TalkingFace/Models.zip\n",
        "!cp -r Models/Audio .\n",
        "!cp -r Models/Deep3DFaceReconstruction .\n",
        "!cp -r Models/render-to-video ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O9MpMLZISUe"
      },
      "source": [
        "## Fine-tuning on a person"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9VhkX8AHolU"
      },
      "source": [
        "### Extract frames\n",
        "\n",
        "Use the 25fps example video 31.mp4 as an example.\n",
        "For your video, need to convert to 25 fps using ffmpeg, and rename to [number].mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4hd4ziGe2S8l",
        "outputId": "4c73e985-73a3-4cb1-fe30-05981843723b"
      },
      "outputs": [],
      "source": [
        "!cd Data/; python extract_frame1.py 31.mp4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMp339b6H0tF"
      },
      "source": [
        "### Something wrong with tensorflow-gpu, better uninstall and install again..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "30gvMjpm4Jiw",
        "outputId": "63c925d5-1652-477d-b826-10ee730591c0"
      },
      "outputs": [],
      "source": [
        "!pip list | grep tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gkR5EorHGcJS",
        "outputId": "38176bf9-cec8-4733-ec29-6220fb8cfe2f"
      },
      "outputs": [],
      "source": [
        "!pip uninstall tensorflow tensorflow-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "dlpYqryQG3Kv",
        "outputId": "34c248b3-4408-4f13-b1a5-d5b5166c0329"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-gpu==1.14.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u277dOUcHo8i"
      },
      "source": [
        "### Build tf_mesh_renderer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mf_OjEGe7vZe"
      },
      "outputs": [],
      "source": [
        "!cp /usr/local/lib/python3.6/dist-packages/tensorflow/libtensorflow_framework.so.1 /usr/lib/\n",
        "!cd /usr/lib/ && ln -s libtensorflow_framework.so.1 libtensorflow_framework.so\n",
        "!cd Deep3DFaceReconstruction/tf_mesh_renderer/mesh_renderer/kernels/;\\\n",
        "  g++ -std=c++11 -shared rasterize_triangles_grad.cc rasterize_triangles_op.cc rasterize_triangles_impl.cc rasterize_triangles_impl.h -o rasterize_triangles_kernel.so -fPIC -D_GLIBCXX_USE_CXX11_ABI=0 -I /usr/local/lib/python3.6/dist-packages/tensorflow/include -I /usr/local/lib/python3.6/dist-packages/tensorflow/include/external/nsync/public -L /usr/local/lib/python3.6/dist-packages/tensorflow -ltensorflow_framework -O2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ynp--weHRTw"
      },
      "source": [
        "### Edit rasterize_triangles.py using pycat and %%writefile\n",
        "\n",
        "28 line: change to os.path.join('/content/Audio-driven-TalkingFace-HeadPose/Deep3DFaceReconstruction',"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXug09AxFzXw"
      },
      "outputs": [],
      "source": [
        "pycat Deep3DFaceReconstruction/tf_mesh_renderer/mesh_renderer/rasterize_triangles.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "k0RO5gWcGI6Y",
        "outputId": "49f7c78c-a03e-4cc9-d5f5-50bfcd93da98"
      },
      "outputs": [],
      "source": [
        "%%writefile Deep3DFaceReconstruction/tf_mesh_renderer/mesh_renderer/rasterize_triangles.py\n",
        "# Copyright 2017 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Differentiable triangle rasterizer.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from . import camera_utils\n",
        "\n",
        "rasterize_triangles_module = tf.load_op_library(\n",
        "    #os.path.join(os.environ['TEST_SRCDIR'],\n",
        "    os.path.join('/content/Audio-driven-TalkingFace-HeadPose/Deep3DFaceReconstruction',\n",
        "    'tf_mesh_renderer/mesh_renderer/kernels/rasterize_triangles_kernel.so'))\n",
        "\n",
        "\n",
        "def rasterize(world_space_vertices, attributes, triangles, camera_matrices,\n",
        "              image_width, image_height, background_value):\n",
        "  \"\"\"Rasterizes a mesh and computes interpolated vertex attributes.\n",
        "\n",
        "  Applies projection matrices and then calls rasterize_clip_space().\n",
        "\n",
        "  Args:\n",
        "    world_space_vertices: 3-D float32 tensor of xyz positions with shape\n",
        "      [batch_size, vertex_count, 3].\n",
        "    attributes: 3-D float32 tensor with shape [batch_size, vertex_count,\n",
        "      attribute_count]. Each vertex attribute is interpolated across the\n",
        "      triangle using barycentric interpolation.\n",
        "    triangles: 2-D int32 tensor with shape [triangle_count, 3]. Each triplet\n",
        "      should contain vertex indices describing a triangle such that the\n",
        "      triangle's normal points toward the viewer if the forward order of the\n",
        "      triplet defines a clockwise winding of the vertices. Gradients with\n",
        "      respect to this tensor are not available.\n",
        "    camera_matrices: 3-D float tensor with shape [batch_size, 4, 4] containing\n",
        "      model-view-perspective projection matrices.\n",
        "    image_width: int specifying desired output image width in pixels.\n",
        "    image_height: int specifying desired output image height in pixels.\n",
        "    background_value: a 1-D float32 tensor with shape [attribute_count]. Pixels\n",
        "      that lie outside all triangles take this value.\n",
        "\n",
        "  Returns:\n",
        "    A 4-D float32 tensor with shape [batch_size, image_height, image_width,\n",
        "    attribute_count], containing the interpolated vertex attributes at\n",
        "    each pixel.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: An invalid argument to the method is detected.\n",
        "  \"\"\"\n",
        "  clip_space_vertices = camera_utils.transform_homogeneous(\n",
        "      camera_matrices, world_space_vertices)\n",
        "  return rasterize_clip_space(clip_space_vertices, attributes, triangles,\n",
        "                              image_width, image_height, background_value)\n",
        "\n",
        "\n",
        "def rasterize_clip_space(clip_space_vertices, attributes, triangles,\n",
        "                         image_width, image_height, background_value):\n",
        "  \"\"\"Rasterizes the input mesh expressed in clip-space (xyzw) coordinates.\n",
        "\n",
        "  Interpolates vertex attributes using perspective-correct interpolation and\n",
        "  clips triangles that lie outside the viewing frustum.\n",
        "\n",
        "  Args:\n",
        "    clip_space_vertices: 3-D float32 tensor of homogenous vertices (xyzw) with\n",
        "      shape [batch_size, vertex_count, 4].\n",
        "    attributes: 3-D float32 tensor with shape [batch_size, vertex_count,\n",
        "      attribute_count]. Each vertex attribute is interpolated across the\n",
        "      triangle using barycentric interpolation.\n",
        "    triangles: 2-D int32 tensor with shape [triangle_count, 3]. Each triplet\n",
        "      should contain vertex indices describing a triangle such that the\n",
        "      triangle's normal points toward the viewer if the forward order of the\n",
        "      triplet defines a clockwise winding of the vertices. Gradients with\n",
        "      respect to this tensor are not available.\n",
        "    image_width: int specifying desired output image width in pixels.\n",
        "    image_height: int specifying desired output image height in pixels.\n",
        "    background_value: a 1-D float32 tensor with shape [attribute_count]. Pixels\n",
        "      that lie outside all triangles take this value.\n",
        "\n",
        "  Returns:\n",
        "    A 4-D float32 tensor with shape [batch_size, image_height, image_width,\n",
        "    attribute_count], containing the interpolated vertex attributes at\n",
        "    each pixel.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: An invalid argument to the method is detected.\n",
        "  \"\"\"\n",
        "  if not image_width > 0:\n",
        "    raise ValueError('Image width must be > 0.')\n",
        "  if not image_height > 0:\n",
        "    raise ValueError('Image height must be > 0.')\n",
        "  if len(clip_space_vertices.shape) != 3:\n",
        "    raise ValueError('The vertex buffer must be 3D.')\n",
        "\n",
        "  vertex_count = clip_space_vertices.shape[1].value\n",
        "\n",
        "  batch_size = tf.shape(clip_space_vertices)[0]\n",
        "  \n",
        "  per_image_barycentric_coordinates = tf.TensorArray(dtype=tf.float32,\n",
        "    size=batch_size)\n",
        "  per_image_vertex_ids = tf.TensorArray(dtype=tf.int32, size=batch_size)\n",
        "\n",
        "  def batch_loop_condition(b, *args):\n",
        "    return b < batch_size\n",
        "\n",
        "  def batch_loop_iteration(b, per_image_barycentric_coordinates,\n",
        "    per_image_vertex_ids):\n",
        "    barycentric_coords, triangle_ids, _ = (\n",
        "        rasterize_triangles_module.rasterize_triangles(\n",
        "            clip_space_vertices[b, :, :], triangles, image_width,\n",
        "            image_height))\n",
        "    per_image_barycentric_coordinates = \\\n",
        "      per_image_barycentric_coordinates.write(\n",
        "        b, tf.reshape(barycentric_coords, [-1, 3]))\n",
        "\n",
        "    vertex_ids = tf.gather(triangles, tf.reshape(triangle_ids, [-1]))\n",
        "    reindexed_ids = tf.add(vertex_ids, b * clip_space_vertices.shape[1].value)\n",
        "    per_image_vertex_ids = per_image_vertex_ids.write(b, reindexed_ids)\n",
        "\n",
        "    return b+1, per_image_barycentric_coordinates, per_image_vertex_ids\n",
        "\n",
        "  b = tf.constant(0)\n",
        "  _, per_image_barycentric_coordinates, per_image_vertex_ids = tf.while_loop(\n",
        "    batch_loop_condition, batch_loop_iteration,\n",
        "    [b, per_image_barycentric_coordinates, per_image_vertex_ids])\n",
        "\n",
        "  barycentric_coordinates = tf.reshape(\n",
        "    per_image_barycentric_coordinates.stack(), [-1, 3])\n",
        "  vertex_ids = tf.reshape(per_image_vertex_ids.stack(), [-1, 3])\n",
        "\n",
        "  # Indexes with each pixel's clip-space triangle's extrema (the pixel's\n",
        "  # 'corner points') ids to get the relevant properties for deferred shading.\n",
        "  flattened_vertex_attributes = tf.reshape(attributes,\n",
        "                                           [batch_size * vertex_count, -1])\n",
        "  corner_attributes = tf.gather(flattened_vertex_attributes, vertex_ids)\n",
        "\n",
        "  # Computes the pixel attributes by interpolating the known attributes at the\n",
        "  # corner points of the triangle interpolated with the barycentric coordinates.\n",
        "  weighted_vertex_attributes = tf.multiply(\n",
        "      corner_attributes, tf.expand_dims(barycentric_coordinates, axis=2))\n",
        "  summed_attributes = tf.reduce_sum(weighted_vertex_attributes, axis=1)\n",
        "  attribute_images = tf.reshape(summed_attributes,\n",
        "                                [batch_size, image_height, image_width, -1])\n",
        "\n",
        "  # Barycentric coordinates should approximately sum to one where there is\n",
        "  # rendered geometry, but be exactly zero where there is not.\n",
        "  alphas = tf.clip_by_value(\n",
        "      tf.reduce_sum(2.0 * barycentric_coordinates, axis=1), 0.0, 1.0)\n",
        "  alphas = tf.reshape(alphas, [batch_size, image_height, image_width, 1])\n",
        "\n",
        "  attributes_with_background = (\n",
        "      alphas * attribute_images + (1.0 - alphas) * background_value)\n",
        "\n",
        "  return attributes_with_background\n",
        "\n",
        "\n",
        "@tf.RegisterGradient('RasterizeTriangles')\n",
        "def _rasterize_triangles_grad(op, df_dbarys, df_dids, df_dz):\n",
        "  # Gradients are only supported for barycentric coordinates. Gradients for the\n",
        "  # z-buffer are not currently implemented. If you need gradients w.r.t. z,\n",
        "  # include z as a vertex attribute when calling rasterize_triangles.\n",
        "  del df_dids, df_dz\n",
        "  return rasterize_triangles_module.rasterize_triangles_grad(\n",
        "      op.inputs[0], op.inputs[1], op.outputs[0], op.outputs[1], df_dbarys,\n",
        "      op.get_attr('image_width'), op.get_attr('image_height')), None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8l6opkOouEu9",
        "outputId": "ff20a5e0-f82f-4ae2-ac8d-2e99ec3873e8"
      },
      "outputs": [],
      "source": [
        "%%writefile Audio/code/mesh_renderer/rasterize_triangles.py\n",
        "# Copyright 2017 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"Differentiable triangle rasterizer.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from . import camera_utils\n",
        "\n",
        "rasterize_triangles_module = tf.load_op_library(\n",
        "    #os.path.join(os.environ['TEST_SRCDIR'],\n",
        "    os.path.join('/content/Audio-driven-TalkingFace-HeadPose/Deep3DFaceReconstruction',\n",
        "    'tf_mesh_renderer/mesh_renderer/kernels/rasterize_triangles_kernel.so'))\n",
        "\n",
        "\n",
        "def rasterize(world_space_vertices, attributes, triangles, camera_matrices,\n",
        "              image_width, image_height, background_value):\n",
        "  \"\"\"Rasterizes a mesh and computes interpolated vertex attributes.\n",
        "\n",
        "  Applies projection matrices and then calls rasterize_clip_space().\n",
        "\n",
        "  Args:\n",
        "    world_space_vertices: 3-D float32 tensor of xyz positions with shape\n",
        "      [batch_size, vertex_count, 3].\n",
        "    attributes: 3-D float32 tensor with shape [batch_size, vertex_count,\n",
        "      attribute_count]. Each vertex attribute is interpolated across the\n",
        "      triangle using barycentric interpolation.\n",
        "    triangles: 2-D int32 tensor with shape [triangle_count, 3]. Each triplet\n",
        "      should contain vertex indices describing a triangle such that the\n",
        "      triangle's normal points toward the viewer if the forward order of the\n",
        "      triplet defines a clockwise winding of the vertices. Gradients with\n",
        "      respect to this tensor are not available.\n",
        "    camera_matrices: 3-D float tensor with shape [batch_size, 4, 4] containing\n",
        "      model-view-perspective projection matrices.\n",
        "    image_width: int specifying desired output image width in pixels.\n",
        "    image_height: int specifying desired output image height in pixels.\n",
        "    background_value: a 1-D float32 tensor with shape [attribute_count]. Pixels\n",
        "      that lie outside all triangles take this value.\n",
        "\n",
        "  Returns:\n",
        "    A 4-D float32 tensor with shape [batch_size, image_height, image_width,\n",
        "    attribute_count], containing the interpolated vertex attributes at\n",
        "    each pixel.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: An invalid argument to the method is detected.\n",
        "  \"\"\"\n",
        "  clip_space_vertices = camera_utils.transform_homogeneous(\n",
        "      camera_matrices, world_space_vertices)\n",
        "  return rasterize_clip_space(clip_space_vertices, attributes, triangles,\n",
        "                              image_width, image_height, background_value)\n",
        "\n",
        "\n",
        "def rasterize_clip_space(clip_space_vertices, attributes, triangles,\n",
        "                         image_width, image_height, background_value):\n",
        "  \"\"\"Rasterizes the input mesh expressed in clip-space (xyzw) coordinates.\n",
        "\n",
        "  Interpolates vertex attributes using perspective-correct interpolation and\n",
        "  clips triangles that lie outside the viewing frustum.\n",
        "\n",
        "  Args:\n",
        "    clip_space_vertices: 3-D float32 tensor of homogenous vertices (xyzw) with\n",
        "      shape [batch_size, vertex_count, 4].\n",
        "    attributes: 3-D float32 tensor with shape [batch_size, vertex_count,\n",
        "      attribute_count]. Each vertex attribute is interpolated across the\n",
        "      triangle using barycentric interpolation.\n",
        "    triangles: 2-D int32 tensor with shape [triangle_count, 3]. Each triplet\n",
        "      should contain vertex indices describing a triangle such that the\n",
        "      triangle's normal points toward the viewer if the forward order of the\n",
        "      triplet defines a clockwise winding of the vertices. Gradients with\n",
        "      respect to this tensor are not available.\n",
        "    image_width: int specifying desired output image width in pixels.\n",
        "    image_height: int specifying desired output image height in pixels.\n",
        "    background_value: a 1-D float32 tensor with shape [attribute_count]. Pixels\n",
        "      that lie outside all triangles take this value.\n",
        "\n",
        "  Returns:\n",
        "    A 4-D float32 tensor with shape [batch_size, image_height, image_width,\n",
        "    attribute_count], containing the interpolated vertex attributes at\n",
        "    each pixel.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: An invalid argument to the method is detected.\n",
        "  \"\"\"\n",
        "  if not image_width > 0:\n",
        "    raise ValueError('Image width must be > 0.')\n",
        "  if not image_height > 0:\n",
        "    raise ValueError('Image height must be > 0.')\n",
        "  if len(clip_space_vertices.shape) != 3:\n",
        "    raise ValueError('The vertex buffer must be 3D.')\n",
        "\n",
        "  vertex_count = clip_space_vertices.shape[1].value\n",
        "\n",
        "  batch_size = tf.shape(clip_space_vertices)[0]\n",
        "  \n",
        "  per_image_barycentric_coordinates = tf.TensorArray(dtype=tf.float32,\n",
        "    size=batch_size)\n",
        "  per_image_vertex_ids = tf.TensorArray(dtype=tf.int32, size=batch_size)\n",
        "\n",
        "  def batch_loop_condition(b, *args):\n",
        "    return b < batch_size\n",
        "\n",
        "  def batch_loop_iteration(b, per_image_barycentric_coordinates,\n",
        "    per_image_vertex_ids):\n",
        "    barycentric_coords, triangle_ids, _ = (\n",
        "        rasterize_triangles_module.rasterize_triangles(\n",
        "            clip_space_vertices[b, :, :], triangles, image_width,\n",
        "            image_height))\n",
        "    per_image_barycentric_coordinates = \\\n",
        "      per_image_barycentric_coordinates.write(\n",
        "        b, tf.reshape(barycentric_coords, [-1, 3]))\n",
        "\n",
        "    vertex_ids = tf.gather(triangles, tf.reshape(triangle_ids, [-1]))\n",
        "    reindexed_ids = tf.add(vertex_ids, b * clip_space_vertices.shape[1].value)\n",
        "    per_image_vertex_ids = per_image_vertex_ids.write(b, reindexed_ids)\n",
        "\n",
        "    return b+1, per_image_barycentric_coordinates, per_image_vertex_ids\n",
        "\n",
        "  b = tf.constant(0)\n",
        "  _, per_image_barycentric_coordinates, per_image_vertex_ids = tf.while_loop(\n",
        "    batch_loop_condition, batch_loop_iteration,\n",
        "    [b, per_image_barycentric_coordinates, per_image_vertex_ids])\n",
        "\n",
        "  barycentric_coordinates = tf.reshape(\n",
        "    per_image_barycentric_coordinates.stack(), [-1, 3])\n",
        "  vertex_ids = tf.reshape(per_image_vertex_ids.stack(), [-1, 3])\n",
        "\n",
        "  # Indexes with each pixel's clip-space triangle's extrema (the pixel's\n",
        "  # 'corner points') ids to get the relevant properties for deferred shading.\n",
        "  flattened_vertex_attributes = tf.reshape(attributes,\n",
        "                                           [batch_size * vertex_count, -1])\n",
        "  corner_attributes = tf.gather(flattened_vertex_attributes, vertex_ids)\n",
        "\n",
        "  # Computes the pixel attributes by interpolating the known attributes at the\n",
        "  # corner points of the triangle interpolated with the barycentric coordinates.\n",
        "  weighted_vertex_attributes = tf.multiply(\n",
        "      corner_attributes, tf.expand_dims(barycentric_coordinates, axis=2))\n",
        "  summed_attributes = tf.reduce_sum(weighted_vertex_attributes, axis=1)\n",
        "  attribute_images = tf.reshape(summed_attributes,\n",
        "                                [batch_size, image_height, image_width, -1])\n",
        "\n",
        "  # Barycentric coordinates should approximately sum to one where there is\n",
        "  # rendered geometry, but be exactly zero where there is not.\n",
        "  alphas = tf.clip_by_value(\n",
        "      tf.reduce_sum(2.0 * barycentric_coordinates, axis=1), 0.0, 1.0)\n",
        "  alphas = tf.reshape(alphas, [batch_size, image_height, image_width, 1])\n",
        "\n",
        "  attributes_with_background = (\n",
        "      alphas * attribute_images + (1.0 - alphas) * background_value)\n",
        "\n",
        "  return attributes_with_background\n",
        "\n",
        "\n",
        "@tf.RegisterGradient('RasterizeTriangles')\n",
        "def _rasterize_triangles_grad(op, df_dbarys, df_dids, df_dz):\n",
        "  # Gradients are only supported for barycentric coordinates. Gradients for the\n",
        "  # z-buffer are not currently implemented. If you need gradients w.r.t. z,\n",
        "  # include z as a vertex attribute when calling rasterize_triangles.\n",
        "  del df_dids, df_dz\n",
        "  return rasterize_triangles_module.rasterize_triangles_grad(\n",
        "      op.inputs[0], op.inputs[1], op.outputs[0], op.outputs[1], df_dbarys,\n",
        "      op.get_attr('image_width'), op.get_attr('image_height')), None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdduS2yyF4kj"
      },
      "source": [
        "### Run 3D face reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UMMlXfKZ4SwL",
        "outputId": "15056531-b878-4e8b-8759-85c3cbdf8f15"
      },
      "outputs": [],
      "source": [
        "!cd Deep3DFaceReconstruction/; CUDA_VISIBLE_DEVICES=0 python demo_19news.py ../Data/31"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmJ1MIPEF8Y6"
      },
      "source": [
        "### Finetune audio net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LCkh_RqyIaX7",
        "outputId": "be24db1d-16ab-47e0-cf62-a9c0eec06b13"
      },
      "outputs": [],
      "source": [
        "!cd Audio/code/; python train_19news_1.py 31 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQoT0XcY_e_G"
      },
      "source": [
        "### Edit render-to-video/train_19news_1.py using pycat and %%writefile\n",
        "\n",
        "change \"matlab -nojvm -nosplash -nodesktop -nodisplay -r\" to \"octave --eval\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGiWb09LKNFz"
      },
      "outputs": [],
      "source": [
        "pycat render-to-video/train_19news_1.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FnluBsbmKioX",
        "outputId": "8bb26d2b-9735-4a5a-97d7-49a2d9d3b9e8"
      },
      "outputs": [],
      "source": [
        "%%writefile render-to-video/train_19news_1.py\n",
        "import os, sys, glob\n",
        "\n",
        "def get_news(n):\n",
        "        trainN=300; testN=100\n",
        "        video = '19_news/'+str(n);name = str(n)+'_bmold_win3';start = 0;\n",
        "        print(video,name)\n",
        "\n",
        "        rootdir = os.path.join(os.getcwd(),'../Deep3DFaceReconstruction/output/render/')\n",
        "        srcdir = os.path.join(rootdir,video)\n",
        "        srcdir2 = srcdir.replace(video,video+'/bm')\n",
        "\n",
        "        if 'bmold' not in name:\n",
        "                cmd = \"cd \"+rootdir+\"/..; octave --eval \\\"pkg load image; alpha_blend_news('\" + video + \"',\" + str(start) + \",\" + str(trainN+testN) + \"); quit;\\\"\"\n",
        "        else:\n",
        "                cmd = \"cd \"+rootdir+\"/..; octave --eval \\\"pkg load image; alpha_blend_newsold('\" + video + \"',\" + str(start) + \",\" + str(trainN+testN) + \"); quit;\\\"\"\n",
        "        os.system(cmd)\n",
        "        if not os.path.exists('datasets/list/trainA'):\n",
        "                os.makedirs('datasets/list/trainA')\n",
        "        if not os.path.exists('datasets/list/trainB'):\n",
        "                os.makedirs('datasets/list/trainB')\n",
        "        f1 = open('datasets/list/trainA/%s.txt'%name,'w')\n",
        "        f2 = open('datasets/list/trainB/%s.txt'%name,'w')\n",
        "        if 'win3' in name:\n",
        "                start1 = start + 2\n",
        "        else:\n",
        "                start1 = start\n",
        "        for i in range(start1,start+trainN):\n",
        "                if 'bmold' not in name:\n",
        "                        print(os.path.join(srcdir2,'frame%d_render_bm.png'%i),file=f1)\n",
        "                else:\n",
        "                        print(os.path.join(srcdir2,'frame%d_renderold_bm.png'%i),file=f1)\n",
        "                print(os.path.join(srcdir,'frame%d.png'%i),file=f2)\n",
        "        f1.close()\n",
        "        f2.close()\n",
        "        if not os.path.exists('datasets/list/testA'):\n",
        "                os.makedirs('datasets/list/testA')\n",
        "        if not os.path.exists('datasets/list/testB'):\n",
        "                os.makedirs('datasets/list/testB')\n",
        "        f1 = open('datasets/list/testA/%s.txt'%name,'w')\n",
        "        f2 = open('datasets/list/testB/%s.txt'%name,'w')\n",
        "        for i in range(start+trainN,start+trainN+testN):\n",
        "                if 'bmold' not in name:\n",
        "                        print(os.path.join(srcdir2,'frame%d_render_bm.png'%i),file=f1)\n",
        "                else:\n",
        "                        print(os.path.join(srcdir2,'frame%d_renderold_bm.png'%i),file=f1)\n",
        "                print(os.path.join(srcdir,'frame%d.png'%i),file=f2)\n",
        "        f1.close()\n",
        "        f2.close()\n",
        "\n",
        "def save_each_60(folder):\n",
        "        pths = sorted(glob.glob(folder+'/*.pth'))\n",
        "        for pth in pths:\n",
        "                epoch = os.path.basename(pth).split('_')[0]\n",
        "                if epoch == '60':\n",
        "                        continue\n",
        "                os.remove(pth)\n",
        "\n",
        "n = int(sys.argv[1])\n",
        "gpu_id = int(sys.argv[2])\n",
        "\n",
        "# prepare training data, and write two txt as training list\n",
        "get_news(n)\n",
        "\n",
        "# prepare arcface feature\n",
        "cmd = 'cd arcface/; python test_batch.py --imglist trainB/%d_bmold_win3.txt --gpu %d' % (n,gpu_id)\n",
        "os.system(cmd)\n",
        "cmd = 'cd arcface/; python test_batch.py --imglist testB/%d_bmold_win3.txt --gpu %d' % (n,gpu_id)\n",
        "os.system(cmd)\n",
        "\n",
        "\n",
        "# fine tune the mapping\n",
        "n = str(n)\n",
        "cmd = 'python train.py --dataroot %s_bmold_win3 --name memory_seq_p2p/%s --model memory_seq --continue_train --epoch 0 --epoch_count 1 --lambda_mask 2 --lr 0.0001 --display_env memory_seq_%s --gpu_ids %d --niter 60 --niter_decay 0' % (n,n,n,gpu_id)\n",
        "os.system(cmd)\n",
        "save_each_60('checkpoints/memory_seq_p2p/%s'%n)\n",
        "\n",
        "epoch = 60\n",
        "cmd = 'python test.py --dataroot %s_bmold_win3 --name memory_seq_p2p/%s --model memory_seq --num_test 200 --epoch %d --gpu_ids %d --imagefolder images%d' % (n,n,epoch,gpu_id,epoch)\n",
        "os.system(cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvC4Y3ANQUy2"
      },
      "source": [
        "### Finetune gan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7k61y-DfyzNQ"
      },
      "source": [
        "Finetune on the target person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "y-To_ualK-4r",
        "outputId": "74716b5f-34f6-44d7-d21e-bed4bab16158"
      },
      "outputs": [],
      "source": [
        "!cd render-to-video/; python train_19news_1.py 31 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKEhmujIUnm7"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3cRqDEyuoyV"
      },
      "source": [
        "### Change matlab in test_personalized.py & test_personalized2.py to octave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpXBoxzzuVAU"
      },
      "outputs": [],
      "source": [
        "pycat Audio/code/test_personalized.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OGnLDIctua-E",
        "outputId": "4b793f6f-4724-4833-9b60-43464e876d57"
      },
      "outputs": [],
      "source": [
        "%%writefile Audio/code/test_personalized.py\n",
        "#encoding:utf-8\n",
        "#test different audio\n",
        "import os\n",
        "from choose_bg_gexinghua2_reassign import choose_bg_gexinghua2_reassign2\n",
        "from trans_with_bigbg import merge_with_bigbg\n",
        "import glob\n",
        "import pdb\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "def getsingle(srcdir,name,varybg=0,multi=0):\n",
        "        srcroot = os.getcwd()\n",
        "        if not varybg:\n",
        "                imgs = glob.glob(os.path.join(srcroot,srcdir,'*_blend.png'))\n",
        "                print('srcdir',os.path.join(srcroot,srcdir,'*_blend.png'))\n",
        "        else:\n",
        "                imgs = glob.glob(os.path.join(srcroot,srcdir,'*_blend2.png'))\n",
        "                print('srcdir',os.path.join(srcroot,srcdir,'*_blend2.png'))\n",
        "        if not os.path.exists('../../render-to-video/datasets/list/testSingle'):\n",
        "                os.makedirs('../../render-to-video/datasets/list/testSingle')\n",
        "        f1 = open('../../render-to-video/datasets/list/testSingle/%s.txt'%name,'w')\n",
        "        imgs = sorted(imgs)\n",
        "        if multi:\n",
        "                imgs = imgs[2:]\n",
        "        for im in imgs:\n",
        "                print(im, file=f1)\n",
        "        f1.close()\n",
        "\n",
        "gpu_id = 0 if len(sys.argv) < 4 else int(sys.argv[3])\n",
        "start=0;ganepoch=60;audioepoch=99\n",
        "\n",
        "\n",
        "audiobasen=sys.argv[1]\n",
        "n = int(sys.argv[2])#person id\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "        person = str(n)\n",
        "        if os.path.exists(os.path.join('../audio/',audiobasen+'.wav')):\n",
        "                in_file = os.path.join('../audio/',audiobasen+'.wav')\n",
        "        elif os.path.exists(os.path.join('../audio/',audiobasen+'.mp3')):\n",
        "                in_file = os.path.join('../audio/',audiobasen+'.mp3')\n",
        "        else:\n",
        "                print('audio file not exists, please put in %s'%os.path.join(os.getcwd(),'../audio'))\n",
        "                exit(-1)\n",
        "\n",
        "        audio_exp_name = 'atcnet_pose0_con3/'+person\n",
        "        audiomodel=os.path.join(audio_exp_name,audiobasen+'_%d'%audioepoch)\n",
        "        sample_dir = os.path.join('../results/',audiomodel)\n",
        "        ganmodel='memory_seq_p2p/%s'%person;post='_full9'\n",
        "        pingyi = 1;\n",
        "        seq='rseq_'+person+'_'+audiobasen+post\n",
        "        if audioepoch == 49:\n",
        "                seq='rseq_'+person+'_'+audiobasen+'_%d%s'%(audioepoch,post)\n",
        "\n",
        "\n",
        "        ## 1.audio to 3dmm\n",
        "        if not os.path.exists(sample_dir+'/00000.npy'):\n",
        "                add = '--model_name ../model/%s/atcnet_lstm_%d.pth --pose 1 --relativeframe 0' % (audio_exp_name,audioepoch)\n",
        "                print('python atcnet_test1.py --device_ids %d %s --sample_dir %s --in_file %s' % (gpu_id,add,sample_dir,in_file))\n",
        "                os.system('python atcnet_test1.py --device_ids %d %s --sample_dir %s --in_file %s' % (gpu_id,add,sample_dir,in_file))\n",
        "\n",
        "        ## 2.background matching\n",
        "        speed=1\n",
        "        num = 300\n",
        "        bgdir = choose_bg_gexinghua2_reassign2('19_news/'+person, audiobasen, start, audiomodel, num=num, tran=pingyi, speed=speed)\n",
        "\n",
        "\n",
        "        ## 3.render to save_dir\n",
        "        coeff_dir = os.path.join(sample_dir,'reassign')\n",
        "        rootdir = '../../Deep3DFaceReconstruction/output/coeff/'\n",
        "        tex2_path = ''\n",
        "        coef_path1 = rootdir+'19_news/'+person+'/frame%d.mat'%start\n",
        "        save_dir = os.path.join(sample_dir,'R_%s_reassign2'%person)\n",
        "        relativeframe = 2\n",
        "        os.system('CUDA_VISIBLE_DEVICES=%d python render_for_view2.py %s %s %s %d %d %s'%(gpu_id,coeff_dir,coef_path1,save_dir, relativeframe,pingyi,tex2_path))\n",
        "\n",
        "\n",
        "        ## 4.blend rendered with background\n",
        "        srcdir = save_dir\n",
        "        #if not os.path.exists(save_dir+'/00000_blend2.png'):\n",
        "        cmd = \"cd ../results; octave --eval \\\"pkg load image; alpha_blend_vbg('\" + bgdir + \"','\" + srcdir + \"'); quit;\\\"\"\n",
        "        os.system(cmd)\n",
        "\n",
        "        ## 5.gan\n",
        "        sample_dir2 = '../../render-to-video/results/%s/test_%d/images%s/'%(ganmodel,ganepoch,seq)\n",
        "        #if not os.path.exists(sample_dir2):\n",
        "        getsingle(save_dir,seq,1,1)\n",
        "        os.system('cd ../../render-to-video; python test_memory.py --dataroot %s --name %s --netG unetac_adain_256 --model test --Nw 3 --norm batch --dataset_mode single_multi --use_memory 1 --attention 1 --num_test 10000 --epoch %d --gpu_ids %d --imagefolder images%s'%(seq,ganmodel,ganepoch,gpu_id,seq))\n",
        "\n",
        "\n",
        "        os.system('cp '+sample_dir2+'/R_'+person+'_reassign2-00002_blend2_fake.png '+sample_dir2+'/R_'+person+'_reassign2-00000_blend2_fake.png')\n",
        "        os.system('cp '+sample_dir2+'/R_'+person+'_reassign2-00002_blend2_fake.png '+sample_dir2+'/R_'+person+'_reassign2-00001_blend2_fake.png')\n",
        "        \n",
        "        video_name = os.path.join(sample_dir,'%s_%swav_results%s.mp4'%(person,audiobasen,post))\n",
        "        command = 'ffmpeg -loglevel panic -framerate 25  -i ' + sample_dir2 +  '/R_' + person + '_reassign2-%05d_blend2_fake.png -c:v libx264 -y -vf format=yuv420p ' + video_name\n",
        "        os.system(command)\n",
        "        command = 'ffmpeg -loglevel panic -i ' + video_name + ' -i ' + in_file + ' -vcodec copy  -acodec copy -y  ' + video_name.replace('.mp4','.mov')\n",
        "        os.system(command)\n",
        "        os.remove(video_name)\n",
        "        print('saved to',video_name.replace('.mp4','.mov'))\n",
        "\n",
        "        merge_with_bigbg(audiobasen,n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65iPLFovA7QL"
      },
      "outputs": [],
      "source": [
        "pycat Audio/code/test_personalized2.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "W8s8GBpxBBXI",
        "outputId": "a416b9ae-5082-487b-dec2-142ba5914489"
      },
      "outputs": [],
      "source": [
        "%%writefile Audio/code/test_personalized2.py\n",
        "#encoding:utf-8\n",
        "#pose from short video\n",
        "import os\n",
        "from trans_with_bigbg import merge_with_bigbg\n",
        "import glob\n",
        "import pdb\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import sys\n",
        "from scipy.io import loadmat,savemat\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "def getsingle(srcdir,name,varybg=0,multi=0):\n",
        "        srcroot = os.getcwd()\n",
        "        if not varybg:\n",
        "                imgs = glob.glob(os.path.join(srcroot,srcdir,'*_blend.png'))\n",
        "                print('srcdir',os.path.join(srcroot,srcdir,'*_blend.png'))\n",
        "        else:\n",
        "                imgs = glob.glob(os.path.join(srcroot,srcdir,'*_blend2.png'))\n",
        "                print('srcdir',os.path.join(srcroot,srcdir,'*_blend2.png'))\n",
        "        if not os.path.exists('../../render-to-video/datasets/list/testSingle'):\n",
        "                os.makedirs('../../render-to-video/datasets/list/testSingle')\n",
        "        f1 = open('../../render-to-video/datasets/list/testSingle/%s.txt'%name,'w')\n",
        "        imgs = sorted(imgs)\n",
        "        if multi:\n",
        "                imgs = imgs[2:]\n",
        "        for im in imgs:\n",
        "                print(im, file=f1)\n",
        "        f1.close()\n",
        "\n",
        "def dreassign2(video, audio, start, audiomodel='', num=300, debug=0, tran=0):\n",
        "        print(video,audio,start,audiomodel)\n",
        "        rootdir = '../..//Deep3DFaceReconstruction/'\n",
        "        matdir = os.path.join(rootdir,'output/coeff',video)\n",
        "        pngdir = os.path.join(rootdir,'output/render',video)\n",
        "        L = 64\n",
        "        folder_to_process = '../results/' + audiomodel\n",
        "        files = sorted(glob.glob(os.path.join(folder_to_process,'*.npy')))\n",
        "        tardir = os.path.join('../results/chosenbg','%s_%s'%(audio,video))\n",
        "        if audiomodel != '':\n",
        "                tardir = os.path.join('../results/chosenbg','%s_%s_%s'%(audio,video,audiomodel.replace('/','_')))\n",
        "        tardir2 = os.path.join(tardir, 'reassign')\n",
        "        print(tardir2)\n",
        "        if not os.path.exists(tardir2):\n",
        "                os.makedirs(tardir2)\n",
        "\n",
        "        sucai = np.zeros((num,6))\n",
        "        lm_5p = np.zeros((num,2))\n",
        "        for i in range(start,start+num):\n",
        "                coeff = loadmat(os.path.join(matdir,'frame%d.mat')%i)\n",
        "                sucai[i-start,:3] = coeff['coeff'][:,224:227]\n",
        "                sucai[i-start,3:] = coeff['coeff'][:,254:257]\n",
        "                if tran:\n",
        "                        lm_5p[i-start,:] = np.mean(coeff['lm_5p'],axis=0)\n",
        "        N = len(files)\n",
        "        datas = np.zeros((N,3))\n",
        "        datasall = np.zeros((N,70))\n",
        "        for i in range(N):\n",
        "                temp = np.load(files[i])\n",
        "                datas[i] = temp[L:L+3]\n",
        "                datasall[i] = temp\n",
        "        # reassign\n",
        "        assigns = [0] * N\n",
        "        for i in range(N):\n",
        "                p = math.floor(i/num) % 2\n",
        "                if p == 0:\n",
        "                        assigns[i] = i%num\n",
        "                else:\n",
        "                        assigns[i] = num-1-(i%num)\n",
        "        print(assigns)\n",
        "        if not os.path.exists(folder_to_process+'/reassign'):\n",
        "                os.mkdir(folder_to_process+'/reassign')\n",
        "        for i in range(N):\n",
        "                if tran == 0:\n",
        "                        data = datasall[i]\n",
        "                        data[L:L+6] = sucai[assigns[i]]\n",
        "                else:\n",
        "                        data = np.zeros((L+9))\n",
        "                        data[:L] = datasall[i,:L]\n",
        "                        data[L:L+6] = sucai[assigns[i]]\n",
        "                        data[L+6:L+8] = lm_5p[assigns[i]]\n",
        "                        data[L+8] = assigns[i]+start\n",
        "                savename = os.path.join(folder_to_process,'reassign','%05d.npy'%i)\n",
        "                np.save(savename, data)\n",
        "                if tran == 0 or tran == 2:\n",
        "                        shutil.copy(os.path.join(pngdir,'frame%d.png'%(assigns[i]+start)),\n",
        "                                os.path.join(tardir2,'%05d.png'%i))\n",
        "                elif tran == 1:\n",
        "                        shutil.copy(os.path.join(pngdir,'frame%d_input2.png'%(assigns[i]+start)),\n",
        "                                os.path.join(tardir2,'%05d.png'%i))\n",
        "        \n",
        "        if debug:\n",
        "                os.system('ffmpeg -loglevel panic -framerate 25 -i ' + tardir2 + '/%05d.png -c:v libx264 -y -vf format=yuv420p ' + tardir2 + '.mp4')\n",
        "        \n",
        "        return tardir2\n",
        "\n",
        "gpu_id = 0 if len(sys.argv) < 4 else int(sys.argv[3])\n",
        "start=0;ganepoch=60;audioepoch=99\n",
        "\n",
        "\n",
        "audiobasen=sys.argv[1]\n",
        "n = int(sys.argv[2])#person id\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "        person = str(n)\n",
        "        if os.path.exists(os.path.join('../audio/',audiobasen+'.wav')):\n",
        "                in_file = os.path.join('../audio/',audiobasen+'.wav')\n",
        "        elif os.path.exists(os.path.join('../audio/',audiobasen+'.mp3')):\n",
        "                in_file = os.path.join('../audio/',audiobasen+'.mp3')\n",
        "        else:\n",
        "                print('audio file not exists, please put in %s'%os.path.join(os.getcwd(),'../audio'))\n",
        "                exit(-1)\n",
        "\n",
        "        audio_exp_name = 'atcnet_pose0_con3/'+person\n",
        "        audiomodel=os.path.join(audio_exp_name,audiobasen+'_%d'%audioepoch)\n",
        "        sample_dir = os.path.join('../results/',audiomodel)\n",
        "        ganmodel='memory_seq_p2p/%s'%person;post='_full9'\n",
        "        pingyi = 1;\n",
        "        seq='rseq_'+person+'_'+audiobasen+post\n",
        "        if audioepoch == 49:\n",
        "                seq='rseq_'+person+'_'+audiobasen+'_%d%s'%(audioepoch,post)\n",
        "\n",
        "\n",
        "        ## 1.audio to 3dmm\n",
        "        if not os.path.exists(sample_dir+'/00000.npy'):\n",
        "                add = '--model_name ../model/%s/atcnet_lstm_%d.pth --pose 1 --relativeframe 0' % (audio_exp_name,audioepoch)\n",
        "                print('python atcnet_test1.py --device_ids %d %s --sample_dir %s --in_file %s' % (gpu_id,add,sample_dir,in_file))\n",
        "                os.system('python atcnet_test1.py --device_ids %d %s --sample_dir %s --in_file %s' % (gpu_id,add,sample_dir,in_file))\n",
        "\n",
        "        ## 2.background matching\n",
        "        num = 300\n",
        "        bgdir = dreassign2('19_news/'+person, audiobasen, start, audiomodel, num=num, tran=pingyi)\n",
        "\n",
        "\n",
        "        ## 3.render to save_dir\n",
        "        coeff_dir = os.path.join(sample_dir,'reassign')\n",
        "        rootdir = '../../Deep3DFaceReconstruction/output/coeff/'\n",
        "        tex2_path = ''\n",
        "        coef_path1 = rootdir+'19_news/'+person+'/frame%d.mat'%start\n",
        "        save_dir = os.path.join(sample_dir,'R_%s_reassign2'%person)\n",
        "        relativeframe = 2\n",
        "        os.system('CUDA_VISIBLE_DEVICES=%d python render_for_view2.py %s %s %s %d %d %s'%(gpu_id,coeff_dir,coef_path1,save_dir, relativeframe,pingyi,tex2_path))\n",
        "\n",
        "\n",
        "        ## 4.blend rendered with background\n",
        "        srcdir = save_dir\n",
        "        #if not os.path.exists(save_dir+'/00000_blend2.png'):\n",
        "        cmd = \"cd ../results; octave --eval \\\"pkg load image; alpha_blend_vbg('\" + bgdir + \"','\" + srcdir + \"'); quit;\\\"\"\n",
        "        os.system(cmd)\n",
        "\n",
        "        ## 5.gan\n",
        "        sample_dir2 = '../../render-to-video/results/%s/test_%d/images%s/'%(ganmodel,ganepoch,seq)\n",
        "        #if not os.path.exists(sample_dir2):\n",
        "        getsingle(save_dir,seq,1,1)\n",
        "        os.system('cd ../../render-to-video; python test_memory.py --dataroot %s --name %s --netG unetac_adain_256 --model test --Nw 3 --norm batch --dataset_mode single_multi --use_memory 1 --attention 1 --num_test 10000 --epoch %d --gpu_ids %d --imagefolder images%s'%(seq,ganmodel,ganepoch,gpu_id,seq))\n",
        "\n",
        "\n",
        "        os.system('cp '+sample_dir2+'/R_'+person+'_reassign2-00002_blend2_fake.png '+sample_dir2+'/R_'+person+'_reassign2-00000_blend2_fake.png')\n",
        "        os.system('cp '+sample_dir2+'/R_'+person+'_reassign2-00002_blend2_fake.png '+sample_dir2+'/R_'+person+'_reassign2-00001_blend2_fake.png')\n",
        "        \n",
        "        video_name = os.path.join(sample_dir,'%s_%swav_results%s.mp4'%(person,audiobasen,post))\n",
        "        command = 'ffmpeg -loglevel panic -framerate 25  -i ' + sample_dir2 +  '/R_' + person + '_reassign2-%05d_blend2_fake.png -c:v libx264 -y -vf format=yuv420p ' + video_name\n",
        "        os.system(command)\n",
        "        command = 'ffmpeg -loglevel panic -i ' + video_name + ' -i ' + in_file + ' -vcodec copy  -acodec copy -y  ' + video_name.replace('.mp4','.mov')\n",
        "        os.system(command)\n",
        "        os.remove(video_name)\n",
        "        print('saved to',video_name.replace('.mp4','.mov'))\n",
        "\n",
        "        merge_with_bigbg(audiobasen,n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISvZzFS4u0f6"
      },
      "source": [
        "### Test on person 31 with audio 03Fsi1831.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "No093apTUlJ7",
        "outputId": "4bdb2b6a-a815-4970-ebda-7ec53c1a8c85"
      },
      "outputs": [],
      "source": [
        "!cd Audio/code/; python test_personalized2.py 03Fsi1831 31 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfbL_VVtwcFC"
      },
      "source": [
        "Results saved to ../results/atcnet_pose0_con3/31/03Fsi1831_99/31_03Fsi1831wav_results_full9.mov\n",
        "and ../results/atcnet_pose0_con3/31/03Fsi1831_99/31_03Fsi1831wav_results_transbigbg.mov"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da-D53H0vnWf"
      },
      "source": [
        "### Show the result video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjROmbymvtZ_"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "video_path = 'Audio/results/atcnet_pose0_con3/31/03Fsi1831_99/31_03Fsi1831wav_results_transbigbg.mov'\n",
        "\n",
        "mp4 = open(video_path,'rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "FQpd7UJ6xOh0",
        "outputId": "487bf9b6-d56b-4ef0-9a5e-984d8282e04c"
      },
      "outputs": [],
      "source": [
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
